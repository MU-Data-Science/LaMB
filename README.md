# LaMB: Harnessing FABRIC for Scalable Language Model Training and Inference

Generative artificial intelligence (AI) services are becoming ubiquitous and directly impacting the daily activities of citizens. These services build on large AI models that require massive amounts of data and computing resources to be trained. Unfortunately, academic users do not have access to such resources and may leverage smaller AI models for specialized applications with limited data. This project seeks to leverage FABRIC (https://portal.fabric-testbed.net), an NSF-funded national distributed computing/networking research infrastructure, to efficiently and securely train AI models and employ them to accelerate research and advance scientific discovery.

# Publications
1. Praveen Rao - **Performance of Small Language Model Pretraining on FABRIC: An Empirical Study**, 11 pages, 2026. [[arXiv preprint]](https://www.arxiv.org/abs/2602.02632)
   
# Team

## Faculty
1. Dr. Praveen Rao (PI)
2. Dr. Deepthi Rao (Senior Personnel) 

## Students
1. Sree Bhargavi Balija (PhD student in CS)
2. Vinaya Santhosh Kumar (PhD student in CS)

# Acknowledgments
This work is supported by the National Science Foundation under Grant No. [2502893](https://www.nsf.gov/awardsearch/showAward?AWD_ID=2502893&HistoricalAwards=false).








